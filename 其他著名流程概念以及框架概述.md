# KOA
Koa 就是一种简单好用的 Web 框架。它的特点是优雅、简洁、表达力强、自由度高。本身代码只有1000多行，所有功能都通过插件实现，很符合 Unix 哲学。
```
$ git clone https://github.com/ruanyf/koa-demos.git
进入示例库，安装依赖。
$ cd koa-demos
$ npm install
```

### 架设 HTTP 服务
```
只要三行代码，就可以用 Koa 架设一个 HTTP 服务。
// demos/01.js
const Koa = require('koa');
const app = new Koa();

app.listen(3000);

运行这个脚本。
$ node demos/01.js
打开浏览器，访问 http://127.0.0.1:3000 。你会看到页面显示"Not Found"，表示没有发现任何内容。这是因为我们并没有告诉 Koa 应该显示什么内容。
```

学习地址：http://www.ruanyifeng.com/blog/2017/08/koa.html

# numpy
NumPy(Numerical Python) 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。

NumPy 的前身 Numeric 最早是由 Jim Hugunin 与其它协作者共同开发，2005 年，Travis Oliphant 在 Numeric 中结合了另一个同性质的程序库 Numarray 的特色，并加入了其它扩展而开发了 NumPy。NumPy 为开放源代码并且由许多协作者共同维护开发。

NumPy 是一个运行速度非常快的数学库，主要用于数组计算，包含：
1. 一个强大的N维数组对象 ndarray
2. 广播功能函数
3. 整合 C/C++/Fortran 代码的工具
4. 线性代数、傅里叶变换、随机数生成等功能

# numpy应用
1. NumPy 通常与 SciPy（Scientific Python）和 Matplotlib（绘图库）一起使用， 这种组合广泛用于替代 MatLab，是一个强大的科学计算环境，有助于我们通过 Python 学习数据科学或者机器学习。
2. SciPy 是一个开源的 Python 算法库和数学工具包。
SciPy 包含的模块有最优化、线性代数、积分、插值、特殊函数、快速傅里叶变换、信号处理和图像处理、常微分方程求解和其他科学与工程中常用的计算。
3. Matplotlib 是 Python 编程语言及其数值数学扩展包 NumPy 的可视化操作界面。它为利用通用的图形用户界面工具包，如 Tkinter, wxPython, Qt 或 GTK+ 向应用程序嵌入式绘图提供了应用程序接口（API）。

相关链接
```
NumPy 官网 http://www.numpy.org/
NumPy 源代码：https://github.com/numpy/numpy
SciPy 官网：https://www.scipy.org/
SciPy 源代码：https://github.com/scipy/scipy
Matplotlib 官网：https://matplotlib.org/
Matplotlib 源代码：https://github.com/matplotlib/matplotlib
```

python在科学计算领域有三个非常受欢迎库，numpy、SciPy、matplotlib。numpy是一个高性能的多维数组的计算库，SciPy是构建在numpy的基础之上的，它提供了许多的操作numpy的数组的函数。SciPy是一款方便、易于使用、专为科学和工程设计的python工具包，它包括了统计、优化、整合以及线性代数模块、傅里叶变换、信号和图像图例，常微分方差的求解等，SciPy完整的教程https://docs.scipy.org/doc/scipy/reference/index.html。下面就简单的介绍一下SciPy在图像处理方面的应用，如果专业做图像处理当然还是建议使用opencv

# pandas
pandas 是基于NumPy 的一种工具，该工具是为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。它是使Python成为强大而高效的数据分析环境的重要因素之一。

### 数据结构
1. Series：一维数组，与Numpy中的一维array类似。二者与Python基本的数据结构List也很相近。Series如今能保存不同种数据类型，字符串、boolean值、数字等都能保存在Series中。
2. Time-Series：以时间为索引的Series。
3. DataFrame：二维的表格型数据结构。很多功能与R中的data.frame类似。可以将DataFrame理解为Series的容器。
4. Panel ：三维的数组，可以理解为DataFrame的容器。

# kafka
Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源 项目。

### Kafka的特性:
- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写

### Kafka的使用场景：
- 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。
- 流式处理：比如spark streaming和storm
- 事件源

### Kakfa的设计思想
- Kakfa Broker Leader的选举：Kakfa Broker集群受Zookeeper管理。所有的Kafka Broker节点一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。（这个过程叫Controller在ZooKeeper注册Watch）。这个Controller会监听其他的Kafka Broker的所有信息，如果这个kafka broker controller宕机了，在zookeeper上面的那个临时节点就会消失，此时所有的kafka broker又会一起去Zookeeper上注册一个临时节点，因为只有一个Kafka Broker会注册成功，其他的都会失败，所以这个成功在Zookeeper上注册临时节点的这个Kafka Broker会成为Kafka Broker Controller，其他的Kafka broker叫Kafka Broker follower。例如：一旦有一个broker宕机了，这个kafka broker controller会读取该宕机broker上所有的partition在zookeeper上的状态，并选取ISR列表中的一个replica作为partition leader（如果ISR列表中的replica全挂，选一个幸存的replica作为leader; 如果该partition的所有的replica都宕机了，则将新的leader设置为-1，等待恢复，等待ISR中的任一个Replica“活”过来，并且选它作为Leader；或选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader），这个broker宕机的事情，kafka controller也会通知zookeeper，zookeeper就会通知其他的kafka broker。

注：

这里曾经发生过一个bug，TalkingData使用Kafka0.8.1的时候，kafka controller在Zookeeper上注册成功后，它和Zookeeper通信的timeout时间是6s，也就是如果kafka controller如果有6s中没有和Zookeeper做心跳，那么Zookeeper就认为这个kafka controller已经死了，就会在Zookeeper上把这个临时节点删掉，那么其他Kafka就会认为controller已经没了，就会再次抢着注册临时节点，注册成功的那个kafka broker成为controller，然后，之前的那个kafka controller就需要各种shut down去关闭各种节点和事件的监听。但是当kafka的读写流量都非常巨大的时候，TalkingData的一个bug是，由于网络等原因，kafka controller和Zookeeper有6s中没有通信，于是重新选举出了一个新的kafka controller，但是原来的controller在shut down的时候总是不成功，这个时候producer进来的message由于Kafka集群中存在两个kafka controller而无法落地。导致数据淤积。
这里曾经还有一个bug，TalkingData使用Kafka0.8.1的时候，当ack=0的时候，表示producer发送出去message，只要对应的kafka broker topic partition leader接收到的这条message，producer就返回成功，不管partition leader 是否真的成功把message真正存到kafka。当ack=1的时候，表示producer发送出去message，同步的把message存到对应topic的partition的leader上，然后producer就返回成功，partition leader异步的把message同步到其他partition replica上。当ack=all或-1，表示producer发送出去message，同步的把message存到对应topic的partition的leader和对应的replica上之后，才返回成功。但是如果某个kafka controller 切换的时候，会导致partition leader的切换（老的 kafka controller上面的partition leader会选举到其他的kafka broker上）,但是这样就会导致丢数据。

https://blog.csdn.net/lingbo229/article/details/80761778
http://kafka.apachecn.org/

# ElasticSearch

# zookeeper

# postgresql

# docker

# Kubernetes

# AWS

# GCP

# Serverless

# TensorFlow

# Microservice

# 异步多线程，协程，socket并发编程

# 理解RPC框架

# 设计高可用，高可靠、高并发、可扩展分布式的平台系统

# DevOps

# 理解 SaaS 的架构原理。

# 微服务、batch、分布式、以及常见架构

# Openstack

# Supervisor

# Selenium

# PhantomS

# 熟悉网络协议NMAP，SNMP及MIB, Onvif，STP




深信服科技集团
1、本科及以上学历，1年以上基础平台、大数据、共性组件领域研发经验，满足三项中的一项即可；
2、精通Elasticsearch、spark、Hbase、Hive、hdfs之一的原理和源码、以及应用，如果同时熟悉Zookeeper、YARN优先考虑；
3、熟悉容器平台开发或者大数据管理工具平台开发，有docker、kubernetes、cdh、ambari相关开发经验更佳；

小I机器人
Python工程师（人工智能方案）
4. 熟练使用pandas、numpy、matplotlib等工具库
5. 熟练使用mongodb、mysql、hadoop等存储
6. 使用过scikit-learn, tensorflow 等机器学习框架优先


Gekko.ai
Python / Golang后端工程师
3.  能熟练运用几种基本的设计模式，熟悉常用的软件架构，熟悉常用数据结构和算法；
4.  熟悉关系/非关系型数据库的使用和基本调试优化；
5.  熟悉高并发编程、缓存、队列、负载均衡，等各种服务端性能调优方案；
6.  有分布式系统开发和部署经验，熟悉docker部署；
7.  优秀的逻辑思维能力、学习能力，良好的沟通能力、团队协作精神；


商汤科技
2. 熟悉并掌握Flask/Django等web框架，了解架构设计和实现原理
3. 熟悉数据库操作，拥有MySQL/MongoDB/Redis等使用经验
4. 了解JavaScript/HTML5/WebSocket等技术
5. 具有Linux/Unix下操作经验
6. 具备良好的团队协作精神，以及积极主动的学习和交流能力
7. 熟悉Git，有开源项目贡献者优先
8. 了解机器学习，有常见深度学习框架（如TensorFlow，PyTorch等）使用经验者优先
9. 了解虚拟化技术，熟悉docker者优先


极光研发中心
3. 熟练掌握Django、Flask等框架，有至少1年实际项目经验，对Web后端技术架构有基本的理解。熟悉常用的部署方案Uwsgi、Nginx、Supervisor等；
4. 熟悉 MySQL、Redis、Celery 等；
5. 熟练使用Git；
6. 有扎实的编程功底，热爱编程，熟悉互联网产品和服务的开发过程；
